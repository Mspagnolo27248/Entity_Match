{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Merge All tables from source A \n",
    "2. Merge All Tables from source B\n",
    "3. Heat map entitys to find dense columns\n",
    "4. Join columns city+ state+ zip code as one \n",
    "5. Clean the features being used by removing special characters and white space\n",
    "6. Create Block feature of the first 4 chars in the name \n",
    "7. use recordlinkage package to compute all possible match pairs for each record in Source A.\n",
    "8. use jarowinkler distance with threshold of .85 to match name and city_state_zip\n",
    "9. Filter the matchs for only those that match within threshold .85 for name and city_state_zip or those two and area_code\n",
    "10. merge source A to the _record_mapping_index and then to source B\n",
    "11. output entity: 'vendor_id','b_entity_id' to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "begin_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read in the Data\n",
    "a_company = pd.read_csv('./data/a__company.csv')\n",
    "a_geo = pd.read_csv('./data/a__geo.csv')\n",
    "b_company = pd.read_csv('./data/b__company.csv')\n",
    "b_address = pd.read_csv('./data/b__address.csv')\n",
    "b_hierarchy = pd.read_csv('./data/b__hierarchy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all Entites of source A\n",
    "a_all = a_company.merge(a_geo,how='left',left_on='geo_id',right_on='geo_id')\n",
    "#a_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all Entites of source B\n",
    "b_all = b_company.merge(b_address,how='left',left_on='b_entity_id',right_on='b_entity_id')\n",
    "#b_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to String and Remove NaN from features and make all lower case.\n",
    "a_all['name'] = a_all['name'].fillna('').astype('str').str.lower() \n",
    "a_all['city'] = a_all['city'].fillna('').astype('str').str.lower() \n",
    "a_all['state'] = a_all['state'].fillna('').astype('str').str.lower()\n",
    "a_all['zipcode_y'] = a_all['zipcode_y'].fillna('').astype('str').str.lower()\n",
    "b_all['entity_name'] = b_all['entity_name'].fillna('').astype('str').str.lower()\n",
    "b_all['city_state_zip'] = b_all['city_state_zip'].fillna('').astype('str').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_names: will remove special characters, whitespace.\n",
    "def clean_names(name):\n",
    "    return ''.join(e for e in name if e.isalnum())\n",
    "\n",
    "#Run clean_names on the name entities\n",
    "a_all['a_clean_name'] = a_all['name'].apply(clean_names)\n",
    "b_all['b_clean_name'] = b_all['entity_name'].apply(clean_names)\n",
    "\n",
    "#Transform features to create  city_state_zip\n",
    "a_all['a_city_state_zip'] = a_all['city']+a_all['state']+a_all['zipcode_y']\n",
    "b_all['b_city_state_zip'] = b_all['city_state_zip']\n",
    "\n",
    "#Clean the new city_state_zip feature\n",
    "a_all['a_city_state_zip'] = a_all['a_city_state_zip'].apply(clean_names)\n",
    "b_all['b_city_state_zip']  = b_all['b_city_state_zip'].apply(clean_names)\n",
    "\n",
    "#Clean the Area Code\n",
    "a_all['area_code'] = a_all['area_code'].fillna('')\n",
    "b_all['tele_area'] = b_all['tele_area'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Data from A and B to help understand what features we can use.\n",
    "# sns.heatmap(a_all.isnull(), cbar=False).set_title('a_all')\n",
    "# plt.show()\n",
    "# sns.heatmap(b_all.isnull(), cbar=False).set_title('b_all')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_all.to_csv('a_all.csv') #Send all Data to file\n",
    "#b_all.to_csv('b_all.csv') #Send all Data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Blocking Features to A and B\n",
    "a_all['blocks'] = a_all['a_clean_name'].str[0:4]\n",
    "#_all['blocks']\n",
    "b_all['blocks'] = b_all['b_clean_name'].str[0:4]\n",
    "#b_all['blocks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63649784\n"
     ]
    }
   ],
   "source": [
    "import recordlinkage\n",
    "\n",
    "#Make record pairs\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('blocks')\n",
    "candidate_links = indexer.index(a_all,b_all)\n",
    "print(len(candidate_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Algo on Pairs\n",
    "begin_time_match = time.time()\n",
    "compare_cl = recordlinkage.Compare()\n",
    "#jarowinkler or levenshtein\n",
    "compare_cl.string('a_clean_name','b_clean_name',method='jarowinkler',threshold = .85,label='clean_name')\n",
    "compare_cl.string('a_city_state_zip','b_city_state_zip',method='jarowinkler',threshold = .85,label='city_state_zip')\n",
    "#compare_cl.exact('area_code','tele_area',label='area_code')\n",
    "features = compare_cl.compute(candidate_links,a_all,b_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_match = time.time()\n",
    "print('Elapsed time is %f minutes\\n' %float((end_time_match-begin_time_match)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = features.reset_index()\n",
    "#matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = matches[(matches['clean_name']+matches['city_state_zip'])==2]\n",
    "print(len(df))\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_all.loc[7090,['a_clean_name','a_city_state_zip']] # Example Match from Table A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_all.loc[117874,['b_clean_name','b_city_state_zip']] # Example Match from Table B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge Table A with the multiindex mapping and table B\n",
    "output = a_all.merge(df,left_index=True,right_on='level_0')\n",
    "output=output.merge(b_all,how='left',left_on='level_1',right_index=True)\n",
    "#output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(output)) # Length of final output\n",
    "output.loc[:,['a_city_state_zip','b_city_state_zip','a_clean_name','b_clean_name','level_0','level_1']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Mapping\n",
    "output[['vendor_id','b_entity_id']].to_csv('mapping.csv',index=False)\n",
    "       \n",
    "# A more detailed File\n",
    "output.loc[:,['a_city_state_zip','b_city_state_zip','a_clean_name','b_clean_name',\\\n",
    "             'level_0','level_1']].to_csv('output_detail.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print('Elapsed time is %f minutes\\n' %float((end_time-begin_time)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
